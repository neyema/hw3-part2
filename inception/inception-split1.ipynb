{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Sequence\n",
    "import pickle as pkl\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Images Generators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../102flowers/pkl-1/X_train.pkl\", \"rb\") as f:\n",
    "  X_train = pkl.load(f)\n",
    "with open(\"../102flowers/pkl-1/y_train.pkl\", \"rb\") as f:\n",
    "  y_train = pkl.load(f)\n",
    "\n",
    "train_imgs = []\n",
    "for i, path in enumerate(X_train):\n",
    "  img = path.split('\\\\')[-1]\n",
    "  train_imgs.append(f\"../102flowers/102flowers/{img}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../102flowers/pkl-1/X_val.pkl\", \"rb\") as f:\n",
    "  X_val = pkl.load(f)\n",
    "with open(\"../102flowers/pkl-1/y_val.pkl\", \"rb\") as f:\n",
    "  y_val = pkl.load(f)\n",
    "\n",
    "val_imgs = []\n",
    "for i, path in enumerate(X_val):\n",
    "  img = path.split('\\\\')[-1]\n",
    "  val_imgs.append(f\"../102flowers/102flowers/{img}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../102flowers/pkl-1/X_test.pkl\", \"rb\") as f:\n",
    "  X_test = pkl.load(f)\n",
    "with open(\"../102flowers/pkl-1/y_test.pkl\", \"rb\") as f:\n",
    "  y_test = pkl.load(f)\n",
    "\n",
    "test_imgs = []\n",
    "for i, path in enumerate(X_test):\n",
    "  img = path.split('\\\\')[-1]\n",
    "  test_imgs.append(f\"../102flowers/102flowers/{img}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FlowersImagesGenerator(Sequence):\n",
    "\n",
    "  def __init__(self, images_paths, y, num_classes=102, batch_size=32, *args, **kwargs):\n",
    "    self.images_paths = images_paths\n",
    "    self.y = y\n",
    "    self.num_classes = num_classes\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "  def __len__(self):\n",
    "    return (len(self.images_paths) // self.batch_size)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    batch_images = self.images_paths[self.batch_size*index : self.batch_size*(index+1)]\n",
    "    y_batch = self.y[self.batch_size*index : self.batch_size*(index+1)]\n",
    "\n",
    "    X = [cv2.resize(cv2.imread(img_path)/255, (256,256)) for img_path in batch_images]\n",
    "    y_onehot = np.zeros((y_batch.shape[0], self.num_classes))\n",
    "    for i, val in enumerate(y_batch):\n",
    "      y_onehot[i, val - 1] = 1  # y classes are 1 to 102\n",
    "    return np.array(X), y_onehot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_classes = 102"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inception"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inception = InceptionV3(input_shape=(256,256,3),\n",
    "                        include_top=False,\n",
    "                        pooling=max,\n",
    "                        weights='imagenet',\n",
    "                        classes=num_classes,\n",
    "                        classifier_activation='softmax')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for layer in inception.layers:\n",
    "  layer.trainable = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = Flatten()(inception.output)\n",
    "out = Dense(1024, activation='relu', name=\"fc1\")(out)\n",
    "out = Dropout(0.2)(out)\n",
    "predictions = Dense(num_classes, activation='softmax', name=\"predictions\")(out)\n",
    "model = Model(inputs=inception.input, outputs=predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy', 'categorical_accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TestMetricsCallback(Callback):\n",
    "  def __init__(self):\n",
    "    self.epoch_test_loss = []\n",
    "    self.epoch_test_accuracy = []\n",
    "    self.epoch_test_categorical_accuracy = []\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    test_generator = FlowersImagesGenerator(images_paths=test_imgs, y=y_test)\n",
    "    loss, accuracy, categorical_accuracy = self.model.evaluate(test_generator)\n",
    "    self.epoch_test_loss.append(loss)\n",
    "    self.epoch_test_accuracy.append(accuracy)\n",
    "    self.epoch_test_categorical_accuracy.append(categorical_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_generator = FlowersImagesGenerator(images_paths=train_imgs, y=y_train)\n",
    "val_generator = FlowersImagesGenerator(images_paths=val_imgs, y=y_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor='val_loss', mode='min')\n",
    "test_metrics_callback = TestMetricsCallback()\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=50,\n",
    "                    callbacks=[early_stop_callback, test_metrics_callback], verbose=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./history.json\", \"w+\") as f:\n",
    "  json.dump(history.history, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['accuracy'], label='train accuracy')\n",
    "pyplot.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "pyplot.plot(test_metrics_callback.epoch_test_accuracy, label='test accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(loc=\"upper right\")\n",
    "pyplot.show()\n",
    "pyplot.savefig(\"accuracy plot\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['categorical_accuracy'], label='train categorical accuracy')\n",
    "pyplot.plot(history.history['val_categorical_accuracy'], label='val categorical accuracy')\n",
    "pyplot.plot(test_metrics_callback.epoch_test_categorical_accuracy, label='test categorical accuracy')\n",
    "pyplot.ylabel('categorical accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(loc=\"upper right\")\n",
    "pyplot.show()\n",
    "pyplot.savefig(\"categorical accuracy plot\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
